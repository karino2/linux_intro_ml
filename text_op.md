---
title: "テキスト処理関連（grep, sed, awkなど)"
layout: page
---

機械学習では大きなファイルをちょっと切り出す、みたいな事が結構必要になるので、意外と変な知識を要求される。
その分ちょっとした事は諦めてPython使えば良いのでそういうのはやらない。


### grep入門

grepの入門は以下を読む。

- [grep tutorial](http://qpeng.org/computer/grep.htm)
- [Learning to Use Regular Expressions](http://gnosis.cx/publish/programming/regular_expressions.html)

正規表現はこのページで共通して使うのでちょっと大変でも頑張って読もう。


## sed入門

sedは正規表現にマッチした部分を置換するコマンドです。

sedは非常に高機能ですが、機械学習の実務ではセットアップのシェルスクリプトなどでsコマンドを使う程度なので、そこだけ覚えればいいでしょう。
使い方は以下です。

```
sed 's/正規表現/置き換える文字/'
```

置き換える対象は標準入力からとります。普通はパイプで使います。

一行読んでは正規表現にマッチするかテストし、マッチしたらそこを置き換えます。マッチしなかったらそのままその行を出力します。

sは置換をする、というコマンドでs以外にも様々な物がありますが、機械学習では使いません。
少し例を見てみましょう。

例.

```
$ echo "/some/data/0/0001.jpg" | sed 's/\.[a-z]*/.dat/'
/some/data/0/0001.dat
```

なお、sedの/の部分は、別の文字に変える事も出来ます。URLやパスなどでスラッシュにマッチさせたい時に便利です。
例えば `sed 's|正規表現|置き換える文字|'` でも良いです（私はこの縦棒を良く使います）。

例.

```
$ echo "/some/data/0/0001.jpg" | sed 's|/[^/]*$|/catalog.json|'
/some/data/0/catalog.json
```


### アドレス指定

デフォルトでは全ての行に対して一行一行処理していきますが、処理する範囲を指定する事も出来ます。処理する範囲の指定をアドレス指定といいます。

プログラマの実務では正規表現の範囲指定を良く使いますが、機械学習では行単位の判定と行数の指定を使う事がたまにある、程度でしょう。行数の指定は凄く限定された使い方なのであとで別にとりあげる事にして、ここでは行判定の記法だけ解説します。

行単位の判定は、sの前に正規表現で指定します。`sed /判定の為の正規表現/s/通常の置換の正規表現/置換対象文字列/`という形になります。

例をあげましょう。以下のようなテキストファイルがあったとします。

```
$ cat test.txt
hoge 123
123
hoge ika 123 fuga
```

これに対してアドレス指定の無いこれまでの置換では、以下のようになります。

```
$ cat test.txt | sed 's/123/999/'
hoge 999
999
hoge ika 999 fuga
```

一方、hogeのある行だけこの置換を行う、という風に書くと以下のようになります。

```
$ cat test.txt | sed '/hoge/s/123/999/'
hoge 999
123
hoge ika 999 fuga
```

二行目が999じゃなくて123のままな事に着目してください。`sed '/hoge/s/123/999/'`は、「正規表現hogeに一致する行に対してだけs以下を実行する」という意味になります。
sedは各行を読んでまず`/hoge/`によるマッチングを試し、マッチしていなければ何もいじらずそのままの行を出力します。
マッチしていたらs以下を実行します。


### マッチした所だけ出力する（nとp）

アドレス指定と組み合わせて良く使われる機能として、nオプションとpコマンドがあります。
nオプションは基本的には出力をしない、という動作を行うオプションです。
これだけでは何も表示されなくなって意味が無いので、処理した所だけ表示する、というpというコマンドと組わせます。

構文としては以下のようになります。`sed -n 's/正規表現/置換文字列/p'` このようにsedのコマンドラインオプションに`-n`を指定し、
置換の書式の最後に`p`を追加します。

先ほどのtest.txtの、今度はhogeをZZZに置き換えてみましょう。

```
$ cat test.txt | sed -n 's/hoge/ZZZ/p'
ZZZ 123
ZZZ ika 123 fuga
```

二行目の123が表示されなくなった事が分かると思います。

### 行数によるアドレス指定

アドレス指定には、行数を指定する事が出来ます。これは「X行からY行まで抜き出す」という用途でしか使われないので、
具体例を見れば十分でしょう。

10行目から15行目まで表示したいなら、`sed -n '10,15p'`とします。
headとtailをあわせたような振る舞いですね。

```
$ env | sed -n '10,15p'
GOPATH=/home/karino2/go/1.13.1
PWD=/home/karino2/Documents/linux_intro_ml
HOME=/home/karino2
GOROOT=/home/karino2/.goenv/versions/1.13.1
NAME=LETS-NOTE-RZ4
XDG_DATA_DIRS=/usr/local/share:/usr/share:/var/lib/snapd/desktop
```

これは大規模なテキストデータの一部を抜き出していろいろ調査する時に、アドホックに作業する時に良く使います。

なお、headとtailを組み合わせた`env | head -n 15 | tail -n 6`でも同じ結果が得られます。

### 機械学習で使った例、Jupyterのtokenだけを出力する

自分が機械学習関連で使ったシェルスクリプトには以下のような物がありました。

```
#!/bin/sh

jupyter-notebook --ip=0.0.0.0 2>&1 | tee notebook_output.log | sed -n "/^ *http.*8888/s/ *http.*token=//p"
```

teeは標準入力を、引数のファイルと標準出力の両方に出力する、というコマンドです。
ローマ字の「T」の形から来た名前で、パイプを横にそのまま出力を流しつつ下にも落とす、みたいなイメージでしょうか。
何かトラブルが出た時にnotebook_output.logを見たり別のターミナルなどから`tail -f notebook_output.log`で張り付いて長いコマンドが実行されるのをまったりするのに使いますが、今回のsedの理解としては取り払っても同じです。

sedに集中する為に、同じ処理になる以下のような例を見てみましょう。

```
$ cat notebook_output.log | sed -n "/^ *http.*8888/s/ *http.*token=//p"
```

notebook_output.logは以下のような内容とします（試したければ自分でエディタでnotebook_output.logというファイルを作ってコピペしてください）。

```
$ cat notebook_output.log
[I 00:57:58.873 NotebookApp] Serving notebooks from local directory: /work
[I 00:57:58.874 NotebookApp] The Jupyter Notebook is running at:
[I 00:57:58.875 NotebookApp] http://(88a123b456d or 127.0.0.1):8888/?token=8b27014067bac97736498c7f627635db70142448e37b851a
[I 00:57:58.875 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 00:57:58.876 NotebookApp] No web browser found: could not locate runnable browser.
[C 00:57:58.876 NotebookApp]

    Copy/paste this URL into your browser when you connect for the first time,
    to login with a token:
        http://(88a123b456d or 127.0.0.1):8888/?token=8b27014067bac97736498c7f627635db70142448e37b851a

```

やりたかったのは、この最後の行のtokenより下だけを出力したかった。jupyterを使う時にこれをコピペしなきゃいけないのは機械学習をやっている人なら知っていると思います。

ただ3行目にもhttpを含む行があるので、単純に置換をするだけだとやや面倒なので、アドレス指定をしてこの最後の行だけ出力させたい、と思った。
その為の正規表現が`/^ *http.*8888/`です。

行の先頭から空白が並んで、そのあとhttpがある。念のため8888も入っている事も足してあります。これで3行目はマッチせずに最後の行だけがマッチします。

そして置換としては、`s/ *http.*token=//p`としてます。行頭から`token=`までを全部空文字列に置き換えて、結果としてそこから後ろだけを出力しています。あとで述べる後方参照を使っても良いのですが、不要だったのでこのように書いています。

以上をまとめると、以下のようになります。

```
$  cat notebook_output.log  | sed -n "/^ *http.*8888/s/ *http.*token=//p"
8b27014067bac97736498c7f627635db70142448e37b851a
```

トークンだけ出す方がコピペがちょっとやりやすかったという事ですね。これはスマホのsshアプリからちょっとした動作確認をしたい時に、タッチだけでちょうどコピペする範囲だけを選択するのが辛くて作りました。

TODO: 基本コマンドの方にteeの解説を移す


### 後方参照

機械学習ではあまり使いませんが普通のプログラミング業務では良く使う物に後方参照があります。

置換の時に正規表現の側を`\(`と`\)`囲っておくと、そこにマッチした文字を`置換する文字列`の方で`\1`や`\2`として参照出来ます。
1や2は何番目の括弧にマッチしたかを表します。
例を挙げましょう。

```
$  echo "/some/data/0/0001.jpg" | sed 's|\([0-9]\+\)/\([0-9]\+\).jpg|\1_\2.dat|'
/some/data/0_0001.dat
```

なかなか厳しい正規表現ですね。正規表現は書くのは簡単ですが他人のを読む時はちょっと憂鬱になります。

これは画像分類でMobileNetなどでfeature extractionしたあとに、そのファイルをカテゴリ名とファイル名でまとめて処理したくなった時にやった処理を改変したものです。

もともと「カテゴリid/ファイルid.jpg」という風になっているものを「カテゴリid_ファイルid.dat」に変えたかった訳ですね。

最初の括弧でカテゴリ名に、次の括弧でファイルidにマッチさせています。また、sedではプラスの前にバックスラッシュ（環境によっては円記号）が必要です。
これはawkやPythonとは違う所なので注意しましょう。

もう一つ、先ほどのjupyterの例を改変したものを見てみましょう。

```
$ echo "http://1234:8888/?token=8b27014067bac97736498c7f627635db70142448e37b851a" | sed 's/.*token=\(.*\)/\1/'
8b27014067bac97736498c7f627635db70142448e37b851a
```

こっちの方が先ほどの正規表現よりも筋は良いかもしれませんね。


### さらに勉強したい人は

sedは高機能なので、ちゃんと勉強したい場合はもっとシステマティックに学ぶのが良いと思います。
以下のgnuの公式ドキュメントは十分に良く書けていると思います（少し詳細すぎるとは思いますが）。

[sed, a stream editor](https://www.gnu.org/software/sed/manual/sed.html)

読む時には最初のコマンドラインオプションの山は飛ばして、3.1のsed script overviewあたりから読むと良いでしょう。

sedはかなりいろいろな事が出来るのですが、頑張りすぎると暗号みたいな物になってしまうので、やりすぎないのが大切です。
特に機械学習の場合、チームのメンバのsed力はあまり高くないはずなので、
普通のクラウドプログラマほど同僚の読解力には期待出来ないでしょう。

コマンドラインでのちょっとした処理くらいに留めておくのが正しい機械学習の分析屋だと思います。


# awk入門

awkはsedを拡張してプログラム言語にしたようなコマンドです。
プログラム言語としてはPythonに似ています。

プログラム言語としてちゃんと学ぶとそれなりに機能が多いawkですが、機械学習の分析においては本格的なプログラムはPythonで行う為、awkの出番は対話的にアドホックに大きなテキストを調べたり、ちょっとした環境設定の奥の手として使う程度です。

ここでは機械学習の分析で使う事が多い機能に絞って解説します。

### 簡単な例

解説の前に、幾つか簡単な例を見てみます。実際に動かしてみてください。

まずはls -lの結果をいろいろ見てみます。

```
$ ls -l
total 88
-rwxrwxrwx 1 karino2 karino2  1847 Jan 26 21:55 _config.yml
-rwxrwxrwx 1 karino2 karino2  7987 Jan 26 21:54 index.md
-rwxrwxrwx 1 karino2 karino2 26755 Jan 28 17:29 linux_cmd.md
-rwxrwxrwx 1 karino2 karino2  1092 Jan 27 19:15 machine_admin.md
-rwxrwxrwx 1 karino2 karino2 24968 Feb  5 22:21 shell_intro.md
-rwxrwxrwx 1 karino2 karino2   192 Jan 28 17:15 sync.sh
-rwxrwxrwx 1 karino2 karino2 12611 Feb  6 19:25 text_op.md
```

まずはサイズだけ表示してみましょう。

```
$ ls -l | awk '{print $5}'

1847
7987
26755
1092
24968
192
12709
```

次にこれを足してみます。

```
$ ls -l | awk '{sum += $5} END{print sum}'
76300
```

サイズが5000以上の行だけ表示してみます。

```
$ ls -l | awk '$5>5000'
-rwxrwxrwx 1 karino2 karino2  7987 Jan 26 21:54 index.md
-rwxrwxrwx 1 karino2 karino2 26755 Jan 28 17:29 linux_cmd.md
-rwxrwxrwx 1 karino2 karino2 24968 Feb  5 22:21 shell_intro.md
-rwxrwxrwx 1 karino2 karino2 13489 Feb  6 19:29 text_op.md
```

ファイル名が.mdの物だけのサイズの和を求めてみます。

```
$ ls -l | awk '$9 ~ /.md/{sum += $5} END{print sum}'
74651
```

なお、以下のようにしても同じです。

```
$ ls -l *.md | awk '{sum += $5} END{print sum}'
74651
```

このようにスペースやタブで区切られたテーブルのようなデータをフィルタ的に処理するのがawkの基本となります。


### パターンとアクション

awkのスクリプトはパターンとアクションがワンセットになっていて、それが並んだ物、という構造をしています。

`パターン { アクション }` というのが基本的な構造です。

awkは標準入力から一行ずつ読み込みパターンと一致したらアクションを行う、という事を繰り返す物です。

例えば以下のコマンドの場合、

```
$ ls -l | awk '/.md/{ print $9}'
index.md
linux_cmd.md
machine_admin.md
shell_intro.md
text_op.md
```

パターンは`/.md/`です。今読み込んでいる行と正規表現`.md`がマッチすればアクションが実行されます。

アクションはこの場合`print $9`です。これは9番目のカラムをprintする、という事ですが、詳細はあとで解説します。

パターンとアクションは複数あっても良く、各行に対してそれぞれのパターンが試され、マッチした物はアクションが実行されます。

少し人工的な例ですが、以下をみて下さい。

```
$ ls -l | awk '/.md/{ print $9} /_/{print $9}'
_config.yml
index.md
linux_cmd.md
linux_cmd.md
machine_admin.md
machine_admin.md
shell_intro.md
shell_intro.md
text_op.md
text_op.md
```

各行を読み込み、`.md`にマッチすればファイル名を表示し、`_`にマッチすればファイル名を表示します。
どちらも実行されるので、両方にマッチする場合は二回出力されている事が分かるでしょう。

また、パターンが無い場合は全ての行にマッチします。
`ls -l | awk '{ print $9}'`は全ての行にマッチして、各行の`$9`をprintします。

### ドル変数とFS

awkは、読み込んだ行をフィールドセパレータで区切って`$1, $2, $3...`と順番にドルで始まる変数に入れます。`$0`には区切られていない行全体が入ります。

フィールドセパレータのデフォルトは1回以上連続する空白かタブです。

デフォルト以外のフィールドセパレータが使いたい場合は`-F`オプションで指定出来ます。
正規表現を指定しますが、ほとんどはカンマを指定するくらいだと思います。

例えばenvのようにイコールで区切られるものの場合、以下のようにイコールをフィールドセパレータに指定出来ます。

```
$ env | awk -F '=' '/PATH/{print $1}'
GOPATH
PATH
```

### 変数とNRとNF

特別な変数以外の変数は、初めて使われる時には0の初期値を持ちます。

だから以下のスクリプトは

```
$ ls -l *.md | awk '{sum += $5} END{print sum}'
74651
```

最初にアクションが実行される時はsumが0で、そこにサイズが足されていきます。

なお、ENDは全ての行を読み込み終わって処理が終わったあとの最後に実行される特別なパターンです。

特別な意味を持つ変数として、NRとNFがあります。
Number of RecordsとNumber of Fieldsの略で、NRが現在の行数、NFが現在の行のカラム数になります。

```
$ ls -l | awk '{print NR, NF}'
1 2
2 9
3 9
4 9
5 9
6 9
7 9
8 9
```

## パターンいろいろ

パターンには、

1. 何も無し（デフォルト）
2. BEGINとかEND
3. 正規表現
4. 範囲指定(`/reg_beg/,/reg_end/`のような形)
5. 条件式 (`$5 > 5000`とか)

くらいのパターンがあります。
1はまぁいいと思うので2以降を以下で簡単に解説しておきましょう。

### 2. BEGINとEND

BEGINは一行目を読む前に実行される特別なパターンで、変数の初期化などを行います。
ENDは最後の行の処理が終わったあとに実行される特別なパターンで、集計した結果を表示したりするのに使います。

```
$ ls -l *.md | awk '{sum += $5} END{print sum}'
74651
```

で出てきていますね。最後のENDがそれです。


### 3. 正規表現

正規表現はスラッシュで囲んで記述します。
以下の例では`.md`が正規表現で、各行にこの正規表現がマッチしたらアクションが実行されます。

```
$ ls -l | awk '/.md/{ print $9}'
```


### 4. 範囲指定

ありがちな例ではXMLとかで特定の子要素を取り出す、みたいなのです。
例えばこんなのです。

```
$ cat test.html
<html>
        <body>
                Hello
        </body>
</html>
```

こういうファイルがあったとして、body下だけを取りたい場合は以下。

```
$ cat test.html | awk '/<body>/,/<\/body>/{print $0}'
        <body>
                Hello
        </body>
```

こんな感じで、`/開始の正規表現/,/終了の正規表現/`と書くと、
`開始の正規表現`がマッチした行からアクションが実行されはじめ、
`終了の正規表現`がマッチする行までアクションが実行され続けます。
終了の正規表現よりあとは何も実行されません。

`/<body>/,/<\/body>/`

なお、`print $0`の場合は`$0`は省略して良くて、`print`とだけ書く事も出来ます。
awkのこの手の省略系はたくさんあってキリが無いので、まず冗長でも基本的な書き方を覚えて、良く使うのだけ省略系も覚える、くらいで十分でしょう。

余談ですがこの範囲指定はsedでも同じような記法で指定が出来ます。
機械学習ではうまくこのパターンでsedで扱えるほど綺麗なデータじゃない事が多いのでsedではあまり出番がありませんが。

### 5. 条件式

いろいろ書く。

# 実際の例

citation.csvとかを実際に触ってみる。

